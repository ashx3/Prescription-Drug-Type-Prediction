{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:/New Projects/Prescription Drug Type Prediction/Islander_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>age</th>\n",
       "      <th>Happy_Sad_group</th>\n",
       "      <th>Dosage</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Mem_Score_Before</th>\n",
       "      <th>Mem_Score_After</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bastian</td>\n",
       "      <td>Carrasco</td>\n",
       "      <td>25</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>63.5</td>\n",
       "      <td>61.2</td>\n",
       "      <td>-2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evan</td>\n",
       "      <td>Carrasco</td>\n",
       "      <td>52</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>41.6</td>\n",
       "      <td>40.7</td>\n",
       "      <td>-0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florencia</td>\n",
       "      <td>Carrasco</td>\n",
       "      <td>29</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>59.7</td>\n",
       "      <td>55.1</td>\n",
       "      <td>-4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Holly</td>\n",
       "      <td>Carrasco</td>\n",
       "      <td>50</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>51.7</td>\n",
       "      <td>51.2</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Justin</td>\n",
       "      <td>Carrasco</td>\n",
       "      <td>52</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name last_name  age Happy_Sad_group  Dosage Drug  Mem_Score_Before  \\\n",
       "0    Bastian  Carrasco   25               H       1    A              63.5   \n",
       "1       Evan  Carrasco   52               S       1    A              41.6   \n",
       "2  Florencia  Carrasco   29               H       1    A              59.7   \n",
       "3      Holly  Carrasco   50               S       1    A              51.7   \n",
       "4     Justin  Carrasco   52               H       1    A              47.0   \n",
       "\n",
       "   Mem_Score_After  Diff  \n",
       "0             61.2  -2.3  \n",
       "1             40.7  -0.9  \n",
       "2             55.1  -4.6  \n",
       "3             51.2  -0.5  \n",
       "4             47.1   0.1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198 entries, 0 to 197\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   first_name        198 non-null    object \n",
      " 1   last_name         198 non-null    object \n",
      " 2   age               198 non-null    int64  \n",
      " 3   Happy_Sad_group   198 non-null    object \n",
      " 4   Dosage            198 non-null    int64  \n",
      " 5   Drug              198 non-null    object \n",
      " 6   Mem_Score_Before  198 non-null    float64\n",
      " 7   Mem_Score_After   198 non-null    float64\n",
      " 8   Diff              198 non-null    float64\n",
      "dtypes: float64(3), int64(2), object(4)\n",
      "memory usage: 14.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Functions for Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_name': 139,\n",
       " 'last_name': 18,\n",
       " 'age': 45,\n",
       " 'Happy_Sad_group': 2,\n",
       " 'Dosage': 3,\n",
       " 'Drug': 3,\n",
       " 'Mem_Score_Before': 162,\n",
       " 'Mem_Score_After': 151,\n",
       " 'Diff': 142}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{column : len(data[column].unique()) for column in data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Binary encode the 'Happy_Sad_group' column because it is an categorical variable\n",
    "- 'Drug' column is the target variable and also an categorical variable, so we are not going to change it\n",
    "- Also using OneHotEncoding on the 'first_name' & 'last_name' column in this prediction model because\n",
    "  the dataset only consists of 198 records,<br> \n",
    "  so we cannot get rid of any columns;<br>\n",
    "  Those columns may or may not contribute to the prediction model but due to lack of records but\n",
    "  we are going to continue with those records due to lack of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function creates binary values for categorical variables\n",
    "def onehot_encode(df, column):\n",
    "    df = df.copy()\n",
    "\n",
    "    dummies = pd.get_dummies(df[column], prefix = column)\n",
    "\n",
    "    if len(df[column].unique()) == 2:\n",
    "        dummies = dummies.drop(dummies.columns[0], axis = 1)\n",
    "\n",
    "    df = pd.concat([df, dummies], axis = 1)\n",
    "    df = df.drop(column, axis = 1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function initiates the above function, splits data into 'X' & 'y', train-test-split and scaling X\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # OneHotEncoding categorical features\n",
    "    for column in ['first_name', 'last_name', 'Happy_Sad_group']:\n",
    "        df = onehot_encode(df, column = column)\n",
    "\n",
    "    # Spliting df into 'X' & 'y'\n",
    "    X = df.drop('Drug', axis = 1)\n",
    "    y = df['Drug']\n",
    "\n",
    "    # Train, test & split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n",
    "\n",
    "    # Scale X\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)                # transform returns a Series, so we are converting into a DataFrame\n",
    "    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Dosage</th>\n",
       "      <th>Mem_Score_Before</th>\n",
       "      <th>Mem_Score_After</th>\n",
       "      <th>Diff</th>\n",
       "      <th>first_name_Aaron</th>\n",
       "      <th>first_name_Adam</th>\n",
       "      <th>first_name_Ai</th>\n",
       "      <th>first_name_Akane</th>\n",
       "      <th>first_name_Akira</th>\n",
       "      <th>...</th>\n",
       "      <th>last_name_Lopez</th>\n",
       "      <th>last_name_McCarthy</th>\n",
       "      <th>last_name_Morin</th>\n",
       "      <th>last_name_Novak</th>\n",
       "      <th>last_name_Price</th>\n",
       "      <th>last_name_Rodriguez</th>\n",
       "      <th>last_name_Steiner</th>\n",
       "      <th>last_name_Summers</th>\n",
       "      <th>last_name_Takahashi</th>\n",
       "      <th>Happy_Sad_group_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>-0.302247</td>\n",
       "      <td>1.206716</td>\n",
       "      <td>0.249183</td>\n",
       "      <td>-0.151850</td>\n",
       "      <td>-0.594735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.761340</td>\n",
       "      <td>-0.23116</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.336011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.909251</td>\n",
       "      <td>0.025675</td>\n",
       "      <td>1.221038</td>\n",
       "      <td>1.038471</td>\n",
       "      <td>-0.092208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362143</td>\n",
       "      <td>-0.23116</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.336011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.428464</td>\n",
       "      <td>0.025675</td>\n",
       "      <td>0.438505</td>\n",
       "      <td>-0.684661</td>\n",
       "      <td>-1.707473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362143</td>\n",
       "      <td>-0.23116</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>3.785939</td>\n",
       "      <td>-0.336011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.167603</td>\n",
       "      <td>-1.155366</td>\n",
       "      <td>0.413262</td>\n",
       "      <td>0.698379</td>\n",
       "      <td>0.518003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362143</td>\n",
       "      <td>-0.23116</td>\n",
       "      <td>11.704700</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.336011</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.215712</td>\n",
       "      <td>-1.155366</td>\n",
       "      <td>0.564720</td>\n",
       "      <td>-0.117841</td>\n",
       "      <td>-0.989577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362143</td>\n",
       "      <td>-0.23116</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.336011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>-0.215712</td>\n",
       "      <td>-1.155366</td>\n",
       "      <td>-0.665875</td>\n",
       "      <td>-0.752679</td>\n",
       "      <td>-0.244761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362143</td>\n",
       "      <td>-0.23116</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.336011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1.947677</td>\n",
       "      <td>-1.155366</td>\n",
       "      <td>2.432701</td>\n",
       "      <td>2.370498</td>\n",
       "      <td>0.293661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362143</td>\n",
       "      <td>-0.23116</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.336011</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1.082322</td>\n",
       "      <td>-1.155366</td>\n",
       "      <td>0.552099</td>\n",
       "      <td>0.069210</td>\n",
       "      <td>-0.675498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362143</td>\n",
       "      <td>-0.23116</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.336011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-0.475319</td>\n",
       "      <td>-1.155366</td>\n",
       "      <td>-0.533349</td>\n",
       "      <td>-1.115444</td>\n",
       "      <td>-1.007525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362143</td>\n",
       "      <td>-0.23116</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.336011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-1.254139</td>\n",
       "      <td>0.025675</td>\n",
       "      <td>-0.470242</td>\n",
       "      <td>-0.610974</td>\n",
       "      <td>-0.298603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.761340</td>\n",
       "      <td>-0.23116</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.085436</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.264135</td>\n",
       "      <td>-0.336011</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows Ã— 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age    Dosage  Mem_Score_Before  Mem_Score_After      Diff  \\\n",
       "124 -0.302247  1.206716          0.249183        -0.151850 -0.594735   \n",
       "97   0.909251  0.025675          1.221038         1.038471 -0.092208   \n",
       "42   1.428464  0.025675          0.438505        -0.684661 -1.707473   \n",
       "17  -1.167603 -1.155366          0.413262         0.698379  0.518003   \n",
       "5   -0.215712 -1.155366          0.564720        -0.117841 -0.989577   \n",
       "..        ...       ...               ...              ...       ...   \n",
       "133 -0.215712 -1.155366         -0.665875        -0.752679 -0.244761   \n",
       "137  1.947677 -1.155366          2.432701         2.370498  0.293661   \n",
       "72   1.082322 -1.155366          0.552099         0.069210 -0.675498   \n",
       "140 -0.475319 -1.155366         -0.533349        -1.115444 -1.007525   \n",
       "37  -1.254139  0.025675         -0.470242        -0.610974 -0.298603   \n",
       "\n",
       "     first_name_Aaron  first_name_Adam  first_name_Ai  first_name_Akane  \\\n",
       "124               0.0        -0.121268            0.0         -0.121268   \n",
       "97                0.0        -0.121268            0.0         -0.121268   \n",
       "42                0.0        -0.121268            0.0         -0.121268   \n",
       "17                0.0        -0.121268            0.0         -0.121268   \n",
       "5                 0.0        -0.121268            0.0         -0.121268   \n",
       "..                ...              ...            ...               ...   \n",
       "133               0.0        -0.121268            0.0         -0.121268   \n",
       "137               0.0        -0.121268            0.0         -0.121268   \n",
       "72                0.0        -0.121268            0.0         -0.121268   \n",
       "140               0.0        -0.121268            0.0         -0.121268   \n",
       "37                0.0        -0.121268            0.0         -0.121268   \n",
       "\n",
       "     first_name_Akira  ...  last_name_Lopez  last_name_McCarthy  \\\n",
       "124               0.0  ...         2.761340            -0.23116   \n",
       "97                0.0  ...        -0.362143            -0.23116   \n",
       "42                0.0  ...        -0.362143            -0.23116   \n",
       "17                0.0  ...        -0.362143            -0.23116   \n",
       "5                 0.0  ...        -0.362143            -0.23116   \n",
       "..                ...  ...              ...                 ...   \n",
       "133               0.0  ...        -0.362143            -0.23116   \n",
       "137               0.0  ...        -0.362143            -0.23116   \n",
       "72                0.0  ...        -0.362143            -0.23116   \n",
       "140               0.0  ...        -0.362143            -0.23116   \n",
       "37                0.0  ...         2.761340            -0.23116   \n",
       "\n",
       "     last_name_Morin  last_name_Novak  last_name_Price  last_name_Rodriguez  \\\n",
       "124        -0.085436        -0.085436              0.0            -0.085436   \n",
       "97         -0.085436        -0.085436              0.0            -0.085436   \n",
       "42         -0.085436        -0.085436              0.0            -0.085436   \n",
       "17         11.704700        -0.085436              0.0            -0.085436   \n",
       "5          -0.085436        -0.085436              0.0            -0.085436   \n",
       "..               ...              ...              ...                  ...   \n",
       "133        -0.085436        -0.085436              0.0            -0.085436   \n",
       "137        -0.085436        -0.085436              0.0            -0.085436   \n",
       "72         -0.085436        -0.085436              0.0            -0.085436   \n",
       "140        -0.085436        -0.085436              0.0            -0.085436   \n",
       "37         -0.085436        -0.085436              0.0            -0.085436   \n",
       "\n",
       "     last_name_Steiner  last_name_Summers  last_name_Takahashi  \\\n",
       "124          -0.264135          -0.264135            -0.336011   \n",
       "97           -0.264135          -0.264135            -0.336011   \n",
       "42           -0.264135           3.785939            -0.336011   \n",
       "17           -0.264135          -0.264135            -0.336011   \n",
       "5            -0.264135          -0.264135            -0.336011   \n",
       "..                 ...                ...                  ...   \n",
       "133          -0.264135          -0.264135            -0.336011   \n",
       "137          -0.264135          -0.264135            -0.336011   \n",
       "72           -0.264135          -0.264135            -0.336011   \n",
       "140          -0.264135          -0.264135            -0.336011   \n",
       "37           -0.264135          -0.264135            -0.336011   \n",
       "\n",
       "     Happy_Sad_group_S  \n",
       "124                1.0  \n",
       "97                 1.0  \n",
       "42                 1.0  \n",
       "17                -1.0  \n",
       "5                  1.0  \n",
       "..                 ...  \n",
       "133                1.0  \n",
       "137               -1.0  \n",
       "72                 1.0  \n",
       "140                1.0  \n",
       "37                -1.0  \n",
       "\n",
       "[138 rows x 163 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Logistic Regression trained\n",
      "                   K-Nearest Neighbors trained\n",
      "                         Decision Tree trained\n",
      "Support Vector Machine (Linear Kernel) trained\n",
      "   Support Vector Machine (RBF Kernel) trained\n",
      "                        Neural Network trained\n",
      "                         Random Forest trained\n",
      "                     Gradient Boosting trained\n",
      "                               XGBoost trained\n",
      "                              LightGBM trained\n",
      "                              CatBoost trained\n"
     ]
    }
   ],
   "source": [
    "# Creating a dictionary of the models that we prefer and performing it on the train data\n",
    "models = {\n",
    "    \"                   Logistic Regression\": LogisticRegression(),\n",
    "    \"                   K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"                         Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Support Vector Machine (Linear Kernel)\": LinearSVC(),\n",
    "    \"   Support Vector Machine (RBF Kernel)\": SVC(),\n",
    "    \"                        Neural Network\": MLPClassifier(),\n",
    "    \"                         Random Forest\": RandomForestClassifier(),\n",
    "    \"                     Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"                               XGBoost\": XGBClassifier(eval_metric='mlogloss'),\n",
    "    \"                              LightGBM\": LGBMClassifier(),\n",
    "    \"                              CatBoost\": CatBoostClassifier(verbose=0)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    print(name + \" trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results with accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Logistic Regression: 41.67%\n",
      "                   K-Nearest Neighbors: 36.67%\n",
      "                         Decision Tree: 51.67%\n",
      "Support Vector Machine (Linear Kernel): 40.00%\n",
      "   Support Vector Machine (RBF Kernel): 43.33%\n",
      "                        Neural Network: 41.67%\n",
      "                         Random Forest: 46.67%\n",
      "                     Gradient Boosting: 50.00%\n",
      "                               XGBoost: 38.33%\n",
      "                              LightGBM: 38.33%\n",
      "                              CatBoost: 48.33%\n"
     ]
    }
   ],
   "source": [
    "# After training the model, printing the corresponding model's accuracy\n",
    "for name, model in models.items():\n",
    "    acc = print(name + \": {:.2f}%\".format(model.score(X_test, y_test) * 100))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
